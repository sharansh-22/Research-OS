{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75d71719-e335-467e-bdd6-92e5c27fc743",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing 2 pages from ./data/terminal.pdf\n",
      "INFO:__main__:Extracted 1570 characters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 1570 characters\n",
      "Linux & Terminal Command Cheat Sheet\n",
      "1. File & Directory Navigation\n",
      "pwd\n",
      "ls\n",
      "ls -l\n",
      "ls -a\n",
      "cd folder\n",
      "cd ..\n",
      "cd ../..\n",
      "cd /path/to/dir\n",
      "cd ~\n",
      "cd -\n",
      "2. File & Directory Management\n",
      "touch file.txt\n",
      "mkdir folder\n",
      "mkdir -p a/b/c\n",
      "rm file\n",
      "rm -r folder\n",
      "rm -rf folder\n",
      "cp f1 f2\n",
      "cp -r dir1 dir2\n",
      "mv old new\n",
      "cat file.txt\n",
      "head file.txt\n",
      "tail file.txt\n",
      "tail -f file.txt\n",
      "3. Editing Files\n",
      "nano file.txt\n",
      "vim file.txt\n",
      "code .\n",
      "4. Permissions & Ownership\n",
      "chmod 755 file\n",
      "chmod +x script.sh\n",
      "chown user:group file\n",
      "sudo command\n",
      "5. Search & \n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# OPTIMIZED: Fixed performance issue, added error handling\n",
    "def extract_text_from_pdf(path: str) -> str:\n",
    "    \"\"\"Extract text from PDF with proper error handling\"\"\"\n",
    "    if not Path(path).exists():\n",
    "        raise FileNotFoundError(f\"PDF not found: {path}\")\n",
    "    \n",
    "    try:\n",
    "        text_parts = []  # Use list instead of string concatenation (faster!)\n",
    "        \n",
    "        with pdfplumber.open(path) as pdf:\n",
    "            logger.info(f\"Processing {len(pdf.pages)} pages from {path}\")\n",
    "            \n",
    "            for page_num, page in enumerate(pdf.pages):\n",
    "                page_text = page.extract_text()\n",
    "                \n",
    "                if page_text:\n",
    "                    text_parts.append(page_text)\n",
    "                else:\n",
    "                    logger.warning(f\"Page {page_num + 1} has no extractable text\")\n",
    "            \n",
    "            if not text_parts:\n",
    "                raise ValueError(f\"No extractable text found in {path}\")\n",
    "            \n",
    "            full_text = \"\\n\".join(text_parts)\n",
    "            logger.info(f\"Extracted {len(full_text)} characters\")\n",
    "            return full_text\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to extract from {path}: {e}\")\n",
    "        raise RuntimeError(f\"PDF extraction failed: {e}\") from e\n",
    "\n",
    "# Test it\n",
    "sample_pdf = \"./data/terminal.pdf\"\n",
    "text = extract_text_from_pdf(sample_pdf)\n",
    "print(f\"Extracted {len(text)} characters\")\n",
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c76f07a3-7170-445a-a6ad-83dd985f4a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned text length: 1570\n",
      "Linux & Terminal Command Cheat Sheet\n",
      "1. File & Directory Navigation\n",
      "pwd\n",
      "ls\n",
      "ls -l\n",
      "ls -a\n",
      "cd folder\n",
      "cd ..\n",
      "cd ../..\n",
      "cd /path/to/dir\n",
      "cd ~\n",
      "cd -\n",
      "2. File & Directory Management\n",
      "touch file.txt\n",
      "mkdir folder\n",
      "mkdir -p a/b/c\n",
      "rm file\n",
      "rm -r folder\n",
      "rm -rf folder\n",
      "cp f1 f2\n",
      "cp -r dir1 dir2\n",
      "mv old new\n",
      "cat file.txt\n",
      "head file.txt\n",
      "tail file.txt\n",
      "tail -f file.txt\n",
      "3. Editing Files\n",
      "nano file.txt\n",
      "vim file.txt\n",
      "code .\n",
      "4. Permissions & Ownership\n",
      "chmod 755 file\n",
      "chmod +x script.sh\n",
      "chown user:group file\n",
      "sudo command\n",
      "5. Search & \n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZED: Added input validation\n",
    "def basic_clean(text: str) -> str:\n",
    "    \"\"\"Clean extracted text\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        raise TypeError(f\"Expected string, got {type(text)}\")\n",
    "    \n",
    "    text = text.replace(\"\\r\", \"\\n\")\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "    return text.strip()\n",
    "\n",
    "# Test it\n",
    "clean_text = basic_clean(text)\n",
    "print(f\"Cleaned text length: {len(clean_text)}\")\n",
    "print(clean_text[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba8411c-5ba7-4c37-a4b9-aa86f68c72af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of paragraphs: 1\n",
      "First paragraph preview:\n",
      "Linux & Terminal Command Cheat Sheet\n",
      "1. File & Directory Navigation\n",
      "pwd\n",
      "ls\n",
      "ls -l\n",
      "ls -a\n",
      "cd folder\n",
      "cd ..\n",
      "cd ../..\n",
      "cd /path/to/dir\n",
      "cd ~\n",
      "cd -\n",
      "2. File & Directory Management\n",
      "touch file.txt\n",
      "mkdir folder\n",
      "mkdir -p a/b/c\n",
      "rm file\n",
      "rm -r folder\n",
      "rm -rf folder\n",
      "cp f1 f2\n",
      "cp -r dir1 dir2\n",
      "mv old new\n",
      "cat file.txt\n",
      "head\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZED: Added min length filter\n",
    "def split_into_paragraphs(text: str, min_paragraph_length: int = 10) -> List[str]:\n",
    "    \"\"\"Split text into paragraphs\"\"\"\n",
    "    raw_paragraphs = re.split(r\"\\n{2,}\", text)\n",
    "    paragraphs = [\n",
    "        p.strip() \n",
    "        for p in raw_paragraphs \n",
    "        if p.strip() and len(p.strip()) >= min_paragraph_length\n",
    "    ]\n",
    "    return paragraphs\n",
    "\n",
    "# Test it\n",
    "paragraphs = split_into_paragraphs(clean_text)\n",
    "print(f\"Number of paragraphs: {len(paragraphs)}\")\n",
    "print(f\"First paragraph preview:\\n{paragraphs[0][:300]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7c12fac-d1fe-4375-9ee3-fe6c049313e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Created 2 chunks from 278 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 2\n",
      "First chunk (278 words):\n",
      "Linux & Terminal Command Cheat Sheet 1. File & Directory Navigation pwd ls ls -l ls -a cd folder cd .. cd ../.. cd /path/to/dir cd ~ cd - 2. File & Directory Management touch file.txt mkdir folder mkdir -p a/b/c rm file rm -r folder rm -rf folder cp f1 f2 cp -r dir1 dir2 mv old new cat file.txt head file.txt tail file.txt tail -f file.txt 3. Editing Files nano file.txt vim file.txt code . 4. Permi\n"
     ]
    }
   ],
   "source": [
    "# NEW: Sliding window chunking (works for ALL document types)\n",
    "def build_chunks_sliding_window(\n",
    "    text: str,\n",
    "    chunk_size: int = 300,\n",
    "    overlap: int = 50,\n",
    "    source_name: str = \"document.pdf\"\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Build chunks using sliding window approach\"\"\"\n",
    "    \n",
    "    # ========== INPUT VALIDATION ==========\n",
    "    if not isinstance(text, str):\n",
    "        raise TypeError(f\"text must be string, got {type(text)}\")\n",
    "    \n",
    "    if chunk_size <= 0:\n",
    "        raise ValueError(f\"chunk_size must be positive, got {chunk_size}\")\n",
    "    \n",
    "    if overlap < 0:\n",
    "        raise ValueError(f\"overlap must be non-negative, got {overlap}\")\n",
    "    \n",
    "    if overlap >= chunk_size:\n",
    "        raise ValueError(f\"overlap ({overlap}) must be less than chunk_size ({chunk_size})\")\n",
    "    \n",
    "    if not text.strip():\n",
    "        logger.warning(\"Empty text provided\")\n",
    "        return []\n",
    "    \n",
    "    # ========== SLIDING WINDOW ==========\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    step = chunk_size - overlap\n",
    "    \n",
    "    for i in range(0, len(words), step):\n",
    "        chunk_words = words[i:i + chunk_size]\n",
    "        \n",
    "        # Don't create tiny final chunks\n",
    "        if len(chunk_words) < 10 and chunks:\n",
    "            chunks[-1][\"text\"] += \" \" + \" \".join(chunk_words)\n",
    "            chunks[-1][\"n_words\"] = len(chunks[-1][\"text\"].split())\n",
    "        else:\n",
    "            chunk_text = \" \".join(chunk_words)\n",
    "            chunks.append({\n",
    "                \"id\": len(chunks),\n",
    "                \"text\": chunk_text,\n",
    "                \"n_words\": len(chunk_words),\n",
    "                \"char_count\": len(chunk_text),\n",
    "                \"word_range\": (i, i + len(chunk_words)),\n",
    "                \"source\": source_name\n",
    "            })\n",
    "    \n",
    "    logger.info(f\"Created {len(chunks)} chunks from {len(words)} words\")\n",
    "    return chunks\n",
    "\n",
    "# Test it with the clean text\n",
    "chunks = build_chunks_sliding_window(clean_text, chunk_size=300, overlap=50, source_name=\"terminal.pdf\")\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "print(f\"First chunk ({chunks[0]['n_words']} words):\")\n",
    "print(chunks[0]['text'][:400])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fa91155-a57d-4124-8fdd-756423d403f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Saved 2 chunks to data/chunks/terminal_chunks.jsonl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 2 chunks to data/chunks/terminal_chunks.jsonl\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZED: Added error handling\n",
    "def save_chunks(chunks: List[Dict], output_path: str) -> None:\n",
    "    \"\"\"Save chunks to JSONL file\"\"\"\n",
    "    output_path = Path(output_path)\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    try:\n",
    "        with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "            for chunk in chunks:\n",
    "                f.write(json.dumps(chunk, ensure_ascii=False) + \"\\n\")\n",
    "        \n",
    "        logger.info(f\"Saved {len(chunks)} chunks to {output_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save chunks: {e}\")\n",
    "        raise\n",
    "\n",
    "# Save the chunks\n",
    "output_path = \"data/chunks/terminal_chunks.jsonl\"\n",
    "save_chunks(chunks, output_path)\n",
    "print(f\"Saved {len(chunks)} chunks to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36dbd3dd-b60d-4762-a24c-5a4d10c5e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: Complete end-to-end pipeline\n",
    "def process_pdf(\n",
    "    pdf_path: str,\n",
    "    output_dir: str = \"data/chunks\",\n",
    "    chunk_size: int = 300,\n",
    "    overlap: int = 50\n",
    ") -> List[Dict]:\n",
    "    \"\"\"Complete pipeline: PDF -> Chunks -> Save\"\"\"\n",
    "    logger.info(f\"Processing {pdf_path}\")\n",
    "    \n",
    "    # Extract and clean\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    clean_text = basic_clean(text)\n",
    "    \n",
    "    # Build chunks\n",
    "    source_name = Path(pdf_path).stem + \".pdf\"\n",
    "    chunks = build_chunks_sliding_window(clean_text, chunk_size, overlap, source_name)\n",
    "    \n",
    "    # Save\n",
    "    output_path = Path(output_dir) / f\"{Path(pdf_path).stem}_chunks.jsonl\"\n",
    "    save_chunks(chunks, output_path)\n",
    "    \n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "420fdace-4fe4-4b69-9bee-ae339fdc3a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Created 2 chunks from 278 words\n",
      "INFO:__main__:Created 4 chunks from 278 words\n",
      "INFO:__main__:Created 7 chunks from 278 words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TESTING WITH DIFFERENT CHUNK SIZES\n",
      "============================================================\n",
      "\n",
      "Chunk size 300: 2 chunks\n",
      "Chunk size 100: 4 chunks\n",
      "Chunk size 50: 7 chunks\n",
      "\n",
      "--- Medium Chunk Breakdown ---\n",
      "Chunk 0: 100 words - 'Linux & Terminal Command Cheat Sheet 1. File & Directory Nav...'\n",
      "Chunk 1: 100 words - 'Ownership chmod 755 file chmod +x script.sh chown user:group...'\n",
      "Chunk 2: 100 words - 'apt install pkg sudo apt remove pkg 9. Git Commands git init...'\n",
      "Chunk 3: 38 words - 'script.sh 13. Docker CLI Essentials docker pull image docker...'\n"
     ]
    }
   ],
   "source": [
    "# Test with smaller chunks to see the sliding window in action\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING WITH DIFFERENT CHUNK SIZES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1: Large chunks (current)\n",
    "chunks_large = build_chunks_sliding_window(clean_text, chunk_size=300, overlap=50, source_name=\"terminal.pdf\")\n",
    "print(f\"\\nChunk size 300: {len(chunks_large)} chunks\")\n",
    "\n",
    "# Test 2: Medium chunks\n",
    "chunks_medium = build_chunks_sliding_window(clean_text, chunk_size=100, overlap=20, source_name=\"terminal.pdf\")\n",
    "print(f\"Chunk size 100: {len(chunks_medium)} chunks\")\n",
    "\n",
    "# Test 3: Small chunks\n",
    "chunks_small = build_chunks_sliding_window(clean_text, chunk_size=50, overlap=10, source_name=\"terminal.pdf\")\n",
    "print(f\"Chunk size 50: {len(chunks_small)} chunks\")\n",
    "\n",
    "# Show details for medium chunks\n",
    "print(f\"\\n--- Medium Chunk Breakdown ---\")\n",
    "for i, chunk in enumerate(chunks_medium):\n",
    "    preview = chunk['text'][:60].replace('\\n', ' ')\n",
    "    print(f\"Chunk {i}: {chunk['n_words']} words - '{preview}...'\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
